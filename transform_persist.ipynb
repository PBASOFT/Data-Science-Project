{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-confusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipynb --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "documentary-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.NER import get_entities\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-geometry",
   "metadata": {},
   "source": [
    "### Load csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prime-progressive",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_files/wallstreetbets_26.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-crest",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-amount",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "occasional-wheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns list with submissions dataframe and comments dataframe\n",
    "def transform_reddit_data(data: pd.DataFrame):\n",
    "        dfs = []\n",
    "        # submissions\n",
    "        df_submissions = data.drop(['Unnamed: 0','comment_id', 'fullname', 'parent_id', 'title'],axis=1)\n",
    "        df_submissions['created'] = df_submissions['created'].apply(datetime_to_date)\n",
    "        df_submissions = df_submissions.dropna()\n",
    "        df_submissions.rename(columns = {'post_id':'id'}, inplace = True)\n",
    "        df_submissions['Organizations'] = df_submissions['text'].apply(get_entities).apply(clean_orgs)\n",
    "        dfs.append(df_submissions)\n",
    "        # comments\n",
    "        df_comments = data.drop(['Unnamed: 0', 'fullname', 'post_id', 'title'],axis=1)\n",
    "        df_comments['created'] = df_comments['created'].apply(datetime_to_date)\n",
    "        df_comments = df_comments.dropna()\n",
    "        df_comments['Organizations'] = df_comments['text'].apply(get_entities).apply(clean_orgs)\n",
    "        dfs.append(df_comments)\n",
    "        \n",
    "        return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "tracked-setting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes utc timestamp to datetime.date\n",
    "def datetime_to_date(timestamp):\n",
    "    return pd.to_datetime(timestamp).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "friendly-clearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mentions that we are interested in\n",
    "selected_orgs =  ['AMC', 'Palantir Technologies', 'PLTR', 'FORD', 'Lordstown Motors', 'RIDE', 'Virgin Galactic', 'SPCE', 'AI', 'C3.AI', 'TSLA', 'GE', 'GME', 'AAPL', 'Tesla', 'Apple', 'General Electric', 'GE', 'NOK', 'Nokia']\n",
    "\n",
    "def clean_orgs(organizations):\n",
    "    orgs = []\n",
    "    for org in organizations:\n",
    "        if org in selected_orgs:\n",
    "            orgs.append(org)\n",
    "    return orgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-delaware",
   "metadata": {},
   "source": [
    "## A Look at the mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-rubber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a list of mentionend entities\n",
    "data['Organizations'] = data['text'].apply(get_entities)\n",
    "orgs = data['Organizations'].to_list()\n",
    "orgs_flat = [org for sublist in orgs for org in sublist] # Pulls out entities from the nested lists in orgs => new flat list\n",
    "# Print 20 most mentions ORGs\n",
    "from collections import Counter\n",
    "org_freq = Counter(orgs_flat)\n",
    "org_freq.most_common(20)                                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-testimony",
   "metadata": {},
   "source": [
    "## Save data to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "revised-convertible",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'submisssions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c83175717826>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_reddit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msubmissions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msubmisssions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'submisssions' is not defined"
     ]
    }
   ],
   "source": [
    "dfs = transform_reddit_data(data)\n",
    "submissions = dfs[0]\n",
    "comments = dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUBMISSIONS\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
