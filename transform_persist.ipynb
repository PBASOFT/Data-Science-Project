{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipynb --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "together-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.NER import get_entities\n",
    "import pandas as pd \n",
    "import datetime\n",
    "import requests\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-semiconductor",
   "metadata": {},
   "source": [
    "### Load csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "legal-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_files/wallstreetbets_23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-warehouse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "collect-recipient",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-sterling",
   "metadata": {},
   "source": [
    "## Transforming the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "swiss-kentucky",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns list with submissions dataframe and comments dataframe\n",
    "def transform_reddit_data(data: pd.DataFrame):\n",
    "        dfs = []\n",
    "        # submissions\n",
    "        df_submissions = data.drop(['Unnamed: 0','comment_id', 'fullname', 'parent_id', 'title'],axis=1)\n",
    "        df_submissions['created'] = df_submissions['created'].apply(datetime_to_date)\n",
    "        df_submissions = df_submissions.dropna()\n",
    "        df_submissions.rename(columns = {'post_id':'id'}, inplace = True)\n",
    "        df_submissions['Organizations'] = df_submissions['text'].apply(get_entities).apply(clean_orgs)\n",
    "        dfs.append(df_submissions)\n",
    "        # comments\n",
    "        df_comments = data.drop(['Unnamed: 0', 'fullname', 'post_id', 'title'],axis=1)\n",
    "        df_comments['created'] = df_comments['created'].apply(datetime_to_date)\n",
    "        df_comments = df_comments.dropna()\n",
    "        df_comments['Organizations'] = df_comments['text'].apply(get_entities).apply(clean_orgs)\n",
    "        dfs.append(df_comments)\n",
    "        \n",
    "        return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "passive-handy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes utc timestamp to datetime.date\n",
    "def datetime_to_date(timestamp):\n",
    "    return pd.to_datetime(timestamp).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "advised-radical",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mentions that we are interested in\n",
    "selected_orgs =  ['HKG', 'Alibaba','AMC', 'Palantir Technologies', 'PLTR', 'FORD', 'Lordstown Motors', 'RIDE', 'Virgin Galactic', 'SPCE', 'AI', 'C3.AI', 'TSLA', 'GE', 'GME', 'AAPL', 'Tesla', 'Apple', 'General Electric', 'GE', 'NOK', 'Nokia']\n",
    "orgs_dict = {\"Alibaba\":\"HKG\",\"AMC\":\"AMC\",\"Palantir Technologies\":\"PLTR\",\"FORD\":\"FORD\", \"Lordstown Motors\":\"RIDE\",\"Virgin Galactic\":\"SPCE\",\"c3.AI\":\"AI\",\"Tesla\":\"TSLA\", \"General Electric\":\"GE\",\"Apple\":\"AAPL\",\"GameStop\":\"GME\",\"Gamestop\":\"GME\", \"Nokia\":\"NOK\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "bibliographic-cleaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returning a list of mentioned tickers\n",
    "def clean_orgs(organizations):\n",
    "    orgs = []\n",
    "    for org in organizations:\n",
    "        if org in selected_orgs:\n",
    "            if org in orgs_dict:\n",
    "                org = orgs_dict[org]\n",
    "                orgs.append(org)\n",
    "            else: \n",
    "                orgs.append(org)\n",
    "    for org in orgs:\n",
    "        o = set(orgs)\n",
    "        orgs = list(o)\n",
    "    return orgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "prostate-technique",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SPCE']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_orgs(['Virgin Galactic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-vegetation",
   "metadata": {},
   "source": [
    "## A Look at the mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a list of mentionend entities\n",
    "data['Organizations'] = data['text'].apply(get_entities)\n",
    "orgs = data['Organizations'].to_list()\n",
    "orgs_flat = [org for sublist in orgs for org in sublist] # Pulls out entities from the nested lists in orgs => new flat list\n",
    "# Print 20 most mentions ORGs\n",
    "from collections import Counter\n",
    "org_freq = Counter(orgs_flat)\n",
    "org_freq.most_common(20)                                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-sauce",
   "metadata": {},
   "source": [
    "## Transform and save the data to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "killing-beverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming into lists of submissions and comments\n",
    "dfs = transform_reddit_data(data)\n",
    "submissions = dfs[0]\n",
    "comments = dfs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-anxiety",
   "metadata": {},
   "source": [
    "# THECK IF THERE IS A TIIME INTERVAL MISSING IN A CSV _ IF SO FILL OUT WITH AVERAGE OG TIMEINTERVAL BEFORE AND AFTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "august-enlargement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9225\n"
     ]
    }
   ],
   "source": [
    "## SUBMISSIONS subset\n",
    "#print(len(submissions))\n",
    "#df = submissions[1:500]\n",
    "#insert_submissions(df)\n",
    "#COMMENTS subset\n",
    "print(len(comments))\n",
    "df_c = comments[500:5500]\n",
    "#\n",
    "insert_comments(df_c)\n",
    "\n",
    "#insert_c(df_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "welsh-childhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://localhost:5050/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "smart-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_submissions(dataframe: pd.DataFrame):\n",
    "    \n",
    "    for index, row in dataframe.iterrows():\n",
    "        \n",
    "        #create submission nodes\n",
    "        url2 = 'submission/'+row['subreddit']+'/'+row['created'].strftime('%m-%d-%Y')+'/'+row['id']\n",
    "        response = requests.post(url+url2)\n",
    "        if not response.status_code == 200:\n",
    "            print ('submission id '+ row['id'] + ' failed insertion')\n",
    "        # create mentions relationships\n",
    "        for org in row['Organizations']:\n",
    "            url3 = 'connection/mentions/submission/'+row['id']+'/'+ org\n",
    "            response = requests.post(url+url3)\n",
    "            if not response.status_code == 200:\n",
    "                print ('mentions between '+ row['id'] + ' and ' + org + ' failed creation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "dated-belgium",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_comments(dataframe: pd.DataFrame):\n",
    "    \n",
    "    for index, row in dataframe.iterrows():\n",
    "        \n",
    "        #create comment nodes\n",
    "        url2 = 'comment/'+row['subreddit']+'/'+row['created'].strftime('%m-%d-%Y')+'/'+row['comment_id']+'/'+row['parent_id']\n",
    "        response = requests.post(url+url2)\n",
    "        if not response.status_code == 200:\n",
    "            print ('comment id '+ row['comment_id'] + ' failed insertion')\n",
    "            \n",
    "        # create mentions relationships\n",
    "        for org in row['Organizations']:\n",
    "            url3 = 'connection/mentions/comment/'+row['comment_id']+'/'+ org\n",
    "            response = requests.post(url+url3)\n",
    "            if not response.status_code == 200:\n",
    "                print ('mention between '+ row['comment_id'] + ' and ' + org + ' failed creation')\n",
    "    \n",
    "           \n",
    "        # create replies relationships\n",
    "        row['parent_id'] = pd.Series(row['parent_id'], dtype=\"string\") #turning parent_id from type Series to String\n",
    "        for parent_id in row['parent_id']:\n",
    "            p_id = parent_id[3:]\n",
    "            if parent_id[:2] == 't1':\n",
    "                url_reply = 'connection/replies/comment/' + row['comment_id'] + '/' + p_id\n",
    "            elif parent_id[:2] == 't3':\n",
    "                url_reply = 'connection/replies/submission/' + row['comment_id'] + '/' + p_id\n",
    "            response = requests.post(url+url_reply)\n",
    "            if not response.status_code == 200:\n",
    "                print ('replies relationship between '+ row['comment_id'] + ' and ' + p_id + ' failed creation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-chamber",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-stewart",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-harmony",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-viking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-incidence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-senegal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
