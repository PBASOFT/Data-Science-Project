{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipynb --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "elegant-rover",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ipynb.fs.full.NER'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e600c3cda342>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mipynb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNER\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_entities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipynb.fs.full.NER'"
     ]
    }
   ],
   "source": [
    "from ipynb.fs.full.NER import get_entities\n",
    "import pandas as pd \n",
    "import datetime\n",
    "import requests\n",
    "from collections import Counter\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_entities('this GME is making me rich')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-apparatus",
   "metadata": {},
   "source": [
    "### Load csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_clean = pd.read_csv('data_files/wallstreetbets_21.csv', lineterminator='\\n')\n",
    "data = pd.read_csv('../Data-Science-Project/Data_Collection/data_files/Stocks_34.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-forestry",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('./Data_Collection/data_files/Stocks_3.csv')\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-husband",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_filenames = []\n",
    "old_filenames.append('Data_Collection/data_files/wallstreetbets_50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_filenames.append('Data_Collection/data_files/wallstreetbets_44.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-parliament",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all csv files\n",
    "for file_name in glob.glob('./Data_Collection/data_files/'+'*.csv'):\n",
    "    print('* '+file_name)\n",
    "    if file_name not in old_filenames:\n",
    "        data = pd.read_csv(file_name,lineterminator='\\n')\n",
    "        # Transform data\n",
    "        print('   * Transforming data')\n",
    "        dfs = transform_reddit_data(data)\n",
    "        df_submissions = dfs[0]\n",
    "        df_comments = dfs[1]\n",
    "        # Persist submissions and comments \n",
    "        print('   * Persisting submissions')\n",
    "        insert_submissions(df_submissions)\n",
    "        print('   * Persisting comments')\n",
    "        insert_comments(df_comments)\n",
    "        old_filenames.append(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-prefix",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-american",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Data_Collection/data_files/Stocks_3.csv')\n",
    "df_submissions = data.drop(['Unnamed: 0','comment_id', 'fullname', 'parent_id', 'title'],axis=1)\n",
    "df_submissions['created'] = df_submissions['created'].apply(datetime_to_date)\n",
    "df_submissions = df_submissions.dropna()\n",
    "df_submissions.rename(columns = {'post_id':'id'}, inplace = True)\n",
    "df_submissions['Organizations'] = df_submissions['text'].apply(get_entities).apply(clean_orgs)\n",
    "insert_submissions(df_submissions)\n",
    "df_comments = data.drop(['Unnamed: 0','post_id', 'fullname', 'title'],axis=1)\n",
    "df_comments['created'] = df_comments['created'].apply(datetime_to_date)\n",
    "df_comments = df_comments.dropna()\n",
    "df_comments['Organizations'] = df_comments['text'].apply(get_entities).apply(clean_orgs)\n",
    "insert_comments(df_comments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-chambers",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "insured-laugh",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-document",
   "metadata": {},
   "source": [
    "## Transforming the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns list with submissions dataframe and comments dataframe\n",
    "def transform_reddit_data(data: pd.DataFrame):\n",
    "        dfs = []\n",
    "        # submissions\n",
    "        #candidates =['Unnamed: 0','comment_id', 'fullname', 'parent_id', 'title']\n",
    "        #df_submissions = data.drop([x for x in candidates if x in data.columns], axis=1)\n",
    "        df_submissions = data.drop(['Unnamed: 0','comment_id', 'fullname', 'parent_id', 'title'],axis=1)\n",
    "        df_submissions['created'] = df_submissions['created'].apply(datetime_to_date)\n",
    "        df_submissions = df_submissions.dropna()\n",
    "        df_submissions.rename(columns = {'post_id':'id'}, inplace = True)\n",
    "        df_submissions['Organizations'] = df_submissions['text'].apply(get_entities).apply(clean_orgs)\n",
    "        dfs.append(df_submissions)\n",
    "        # comments\n",
    "        #candidates =['Unnamed: 0','comment_id', 'fullname', 'parent_id', 'title']\n",
    "        #df_comments = data.drop([x for x in candidates if x in data.columns], axis=1)\n",
    "        df_comments = data.drop(['Unnamed: 0','post_id', 'fullname', 'title'],axis=1)\n",
    "        df_comments['created'] = df_comments['created'].apply(datetime_to_date)\n",
    "        df_comments = df_comments.dropna()\n",
    "        df_comments['Organizations'] = df_comments['text'].apply(get_entities).apply(clean_orgs)\n",
    "        dfs.append(df_comments)\n",
    "        \n",
    "        return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-revelation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes utc timestamp to datetime.date\n",
    "def datetime_to_date(timestamp):\n",
    "    return pd.to_datetime(timestamp).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-technique",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mentions that we are interested in\n",
    "selected_orgs =  ['HKG', 'Alibaba','AMC', 'Palantir Technologies', 'PLTR', 'FORD', 'Lordstown Motors', 'RIDE', 'Virgin Galactic', 'SPCE', 'AI', 'C3.AI', 'TSLA', 'GE', 'GME', 'AAPL', 'Tesla', 'Apple', 'General Electric', 'GE', 'NOK', 'Nokia']\n",
    "orgs_dict = {\"Alibaba\":\"HKG\",\"AMC\":\"AMC\",\"Palantir Technologies\":\"PLTR\",\"FORD\":\"FORD\", \"Lordstown Motors\":\"RIDE\",\"Virgin Galactic\":\"SPCE\",\"c3.AI\":\"AI\",\"Tesla\":\"TSLA\", \"General Electric\":\"GE\",\"Apple\":\"AAPL\",\"GameStop\":\"GME\",\"Gamestop\":\"GME\", \"Nokia\":\"NOK\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-russian",
   "metadata": {},
   "source": [
    "Clean orgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-class",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# returning a list of mentioned tickers\n",
    "def clean_orgs(organizations):\n",
    "    orgs = []\n",
    "    for org in organizations:\n",
    "        if org in selected_orgs:\n",
    "            if org in orgs_dict:\n",
    "                org = orgs_dict[org]\n",
    "                orgs.append(org)\n",
    "            else: \n",
    "                orgs.append(org)\n",
    "    for org in orgs:\n",
    "        o = set(orgs)\n",
    "        orgs = list(o)\n",
    "    return orgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-idaho",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_orgs(['Virgin Galactic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-major",
   "metadata": {},
   "source": [
    "## A Look at the mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-boulder",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Creates a list of mentionend entities\n",
    "\n",
    "#data['Organizations'] = data['text'].apply(get_entities)\n",
    "#orgs = data['Organizations'].to_list()\n",
    "#orgs_flat = [org for sublist in orgs for org in sublist] # Pulls out entities from the nested lists in orgs => new flat list\n",
    "# Print 20 most mentions ORGs\n",
    "#from collections import Counter\n",
    "#org_freq = Counter(orgs_flat)\n",
    "#org_freq.most_common(20)                                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-selection",
   "metadata": {},
   "source": [
    "## Transform and save the data to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-calcium",
   "metadata": {},
   "outputs": [],
   "source": [
    "#submissionsransforming into lists of submissions and comments\n",
    "dfs = transform_reddit_data(data)\n",
    "submissions = dfs[0]\n",
    "comments = dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-suite",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## SUBMISSIONS subset\n",
    "#print(len(submissions))\n",
    "df = submissions[1:500]\n",
    "insert_submissions(df)\n",
    "#COMMENTS subset\n",
    "#print(len(comments))\n",
    "#df_c = comments[500:5500]\n",
    "#\n",
    "#insert_comments(df_c)\n",
    "\n",
    "#insert_c(df_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-edwards",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://localhost:5050/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_submissions(dataframe: pd.DataFrame):\n",
    "    \n",
    "    for index, row in dataframe.iterrows():\n",
    "        #create submission nodes\n",
    "        url2 = 'submission/'+row['subreddit']+'/'+row['created'].strftime('%Y-%m-%d')+'/'+row['id']\n",
    "        response = requests.post(url+url2)\n",
    "        if not response.status_code == 200:\n",
    "            print ('submission id '+ row['id'] + ' failed insertion')\n",
    "        # create mentions relationships\n",
    "        for org in row['Organizations']:\n",
    "            url3 = 'connection/mentions/submission/'+row['id']+'/'+ org + '/' + row['created'].strftime('%Y-%m-%d')\n",
    "            response = requests.post(url+url3)\n",
    "            if not response.status_code == 200:\n",
    "                print ('mentions between '+ row['id'] + ' and ' + org + ' failed creation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-defeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_comments(dataframe: pd.DataFrame):\n",
    "    \n",
    "    for index, row in dataframe.iterrows():\n",
    "        \n",
    "        #create comment nodes\n",
    "        url2 = 'comment/'+row['subreddit']+'/'+row['created'].strftime('%m-%d-%Y')+'/'+row['comment_id']+'/'+row['parent_id']\n",
    "        response = requests.post(url+url2)\n",
    "        if not response.status_code == 200:\n",
    "            print ('comment id '+ row['comment_id'] + ' failed insertion')\n",
    "            \n",
    "        # create mentions relationships\n",
    "        for org in row['Organizations']:\n",
    "            url3 = 'connection/mentions/comment/'+row['comment_id']+'/'+ org +'/'+ row['created'].strftime('%m-%d-%Y')\n",
    "            response = requests.post(url+url3)\n",
    "            if not response.status_code == 200:\n",
    "                print ('mention between '+ row['comment_id'] + ' and ' + org + ' failed creation')\n",
    "    \n",
    "           \n",
    "        # create replies relationships\n",
    "        row['parent_id'] = pd.Series(row['parent_id'], dtype=\"string\") #turning parent_id from type Series to String\n",
    "        for parent_id in row['parent_id']:\n",
    "            p_id = parent_id[3:]\n",
    "            if parent_id[:2] == 't1':\n",
    "                url_reply = 'connection/replies/comment/' + row['comment_id'] + '/' + p_id\n",
    "            elif parent_id[:2] == 't3':\n",
    "                url_reply = 'connection/replies/submission/' + row['comment_id'] + '/' + p_id\n",
    "            response = requests.post(url+url_reply)\n",
    "            if not response.status_code == 200:\n",
    "                print ('replies relationship between '+ row['comment_id'] + ' and ' + p_id + ' failed creation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-intersection",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-athletics",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-stable",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-illustration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-munich",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-venezuela",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
