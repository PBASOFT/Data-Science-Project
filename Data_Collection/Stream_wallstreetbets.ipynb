{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "defined-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "functioning-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id = 'p7UHViVl0tL3Kw', \n",
    "                     client_secret = 'C_B_8UNAZatr1So5jJ9qeFmYpuHIyw',\n",
    "                     username = 'bigprojectdsc',\n",
    "                     password = 'BIGproject',\n",
    "                     user_agent =  'smallcaps'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "falling-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "wallstreetbets_subreddit = reddit.subreddit('wallstreetbets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ranging-webcam",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for streaming part\n",
    "df_posts = pd.DataFrame()\n",
    "counter = 30\n",
    "data_folder = \"./data_files/wsb_stream\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "japanese-decrease",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length:\n",
      "1000\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data_files/wsb_streamwallstreetbets_30.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a92928a212c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'length:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_posts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mdf_posts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{data_folder}{subreddit}_{counter}.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mdf_posts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mcounter\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3384\u001b[0m         )\n\u001b[1;32m   3385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3386\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3387\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3388\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         )\n\u001b[0;32m-> 1083\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \"\"\"\n\u001b[1;32m    227\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data_files/wsb_streamwallstreetbets_30.csv'"
     ]
    }
   ],
   "source": [
    "def submissions_and_comments(subreddit, **kwargs):\n",
    "    results = []\n",
    "    results.extend(subreddit.new(**kwargs))\n",
    "    results.extend(subreddit.comments(**kwargs))\n",
    "    results.sort(key=lambda post: post.created_utc, reverse=True)\n",
    "    return results\n",
    "\n",
    "subreddit = wallstreetbets_subreddit\n",
    "stream = praw.models.util.stream_generator(lambda **kwargs: submissions_and_comments(subreddit, **kwargs))\n",
    "        \n",
    "for post in stream:\n",
    "    if len(df_posts.index) >= 1000:\n",
    "        print('length:')\n",
    "        print(len(df_posts.index))\n",
    "        df_posts.to_csv(f\"{data_folder}{subreddit}_{counter}.csv\")\n",
    "        df_posts = pd.DataFrame()\n",
    "        counter+=1\n",
    "    if post.fullname[:2] == 't3':\n",
    "        #submission\n",
    "        df_posts = df_posts.append({\n",
    "            'post_id': post.id,\n",
    "            'title': post.title,\n",
    "            'created': pd.to_datetime(post.created_utc, unit = 's'),\n",
    "            'text': post.selftext,\n",
    "            'subreddit': post.subreddit,\n",
    "            'fullname': post.fullname\n",
    "            }, ignore_index=True)\n",
    "    elif post.fullname[:2] == 't1':\n",
    "        #comment\n",
    "        df_posts = df_posts.append({\n",
    "            'parent_id': post.parent_id,\n",
    "            'comment_id': post.id,\n",
    "            'created': pd.to_datetime(post.created_utc, unit = 's'),\n",
    "            'text': post.body,\n",
    "            'subreddit': post.subreddit,\n",
    "            'fullname': post.fullname\n",
    "            }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "german-sleeve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created</th>\n",
       "      <th>fullname</th>\n",
       "      <th>post_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-28 04:45:41</td>\n",
       "      <td>t3_nmq05j</td>\n",
       "      <td>nmq05j</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>So this is something I can't figure out and I'...</td>\n",
       "      <td>Genuine AMC question (related to any short squ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-28 04:51:18</td>\n",
       "      <td>t3_nmq396</td>\n",
       "      <td>nmq396</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td></td>\n",
       "      <td>$AMC +$208K. Still not selling</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-28 05:06:57</td>\n",
       "      <td>t3_nmqbu4</td>\n",
       "      <td>nmqbu4</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td></td>\n",
       "      <td>$MVIS added to MSCI Small Cap Indexes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-28 05:19:45</td>\n",
       "      <td>t3_nmqiy2</td>\n",
       "      <td>nmqiy2</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td></td>\n",
       "      <td>Just a retarded 🦍over here eating crayons 🚀💰#r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-28 05:28:43</td>\n",
       "      <td>t3_nmqo0s</td>\n",
       "      <td>nmqo0s</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td></td>\n",
       "      <td>AMC as early as 01/27/2021 💎 🤲 🦍 🚀 🌙</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>2021-05-29 23:07:23</td>\n",
       "      <td>t1_gzx4z25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>Rich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gzx4z25</td>\n",
       "      <td>t1_gzx4rkg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>2021-05-29 23:07:24</td>\n",
       "      <td>t1_gzx4z4x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>happy for you friend!\\n\\nngl, i love roulette ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gzx4z4x</td>\n",
       "      <td>t1_gzx43bq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>2021-05-29 23:07:26</td>\n",
       "      <td>t1_gzx4z8c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>Just bought 400 dollars worth let’s hold and s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gzx4z8c</td>\n",
       "      <td>t3_nnurf9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>2021-05-29 23:07:30</td>\n",
       "      <td>t1_gzx4zgy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>27 mph. You’re over here taking pics while dri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gzx4zgy</td>\n",
       "      <td>t1_gzx4g1n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>2021-05-29 23:07:30</td>\n",
       "      <td>t1_gzx4zhm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>Yeah, he was part of the 90s rave scene. He ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gzx4zhm</td>\n",
       "      <td>t1_gecb56a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>879 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                created    fullname post_id       subreddit  \\\n",
       "0   2021-05-28 04:45:41   t3_nmq05j  nmq05j  wallstreetbets   \n",
       "1   2021-05-28 04:51:18   t3_nmq396  nmq396  wallstreetbets   \n",
       "2   2021-05-28 05:06:57   t3_nmqbu4  nmqbu4  wallstreetbets   \n",
       "3   2021-05-28 05:19:45   t3_nmqiy2  nmqiy2  wallstreetbets   \n",
       "4   2021-05-28 05:28:43   t3_nmqo0s  nmqo0s  wallstreetbets   \n",
       "..                  ...         ...     ...             ...   \n",
       "874 2021-05-29 23:07:23  t1_gzx4z25     NaN  wallstreetbets   \n",
       "875 2021-05-29 23:07:24  t1_gzx4z4x     NaN  wallstreetbets   \n",
       "876 2021-05-29 23:07:26  t1_gzx4z8c     NaN  wallstreetbets   \n",
       "877 2021-05-29 23:07:30  t1_gzx4zgy     NaN  wallstreetbets   \n",
       "878 2021-05-29 23:07:30  t1_gzx4zhm     NaN  wallstreetbets   \n",
       "\n",
       "                                                  text  \\\n",
       "0    So this is something I can't figure out and I'...   \n",
       "1                                                        \n",
       "2                                                        \n",
       "3                                                        \n",
       "4                                                        \n",
       "..                                                 ...   \n",
       "874                                               Rich   \n",
       "875  happy for you friend!\\n\\nngl, i love roulette ...   \n",
       "876  Just bought 400 dollars worth let’s hold and s...   \n",
       "877  27 mph. You’re over here taking pics while dri...   \n",
       "878  Yeah, he was part of the 90s rave scene. He ne...   \n",
       "\n",
       "                                                 title comment_id   parent_id  \n",
       "0    Genuine AMC question (related to any short squ...        NaN         NaN  \n",
       "1                       $AMC +$208K. Still not selling        NaN         NaN  \n",
       "2                $MVIS added to MSCI Small Cap Indexes        NaN         NaN  \n",
       "3    Just a retarded 🦍over here eating crayons 🚀💰#r...        NaN         NaN  \n",
       "4                 AMC as early as 01/27/2021 💎 🤲 🦍 🚀 🌙        NaN         NaN  \n",
       "..                                                 ...        ...         ...  \n",
       "874                                                NaN    gzx4z25  t1_gzx4rkg  \n",
       "875                                                NaN    gzx4z4x  t1_gzx43bq  \n",
       "876                                                NaN    gzx4z8c   t3_nnurf9  \n",
       "877                                                NaN    gzx4zgy  t1_gzx4g1n  \n",
       "878                                                NaN    gzx4zhm  t1_gecb56a  \n",
       "\n",
       "[879 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-korean",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-filling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cross-cookie",
   "metadata": {},
   "source": [
    "## HBASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-thriller",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install happybase\n",
    "#!pip3 install virtualenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-there",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "import happybase\n",
    "\n",
    "connection = happybase.Connection('http://localhost:16000/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-distributor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-dylan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-configuration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-concentrate",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_gyezl32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-reynolds",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-processing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
